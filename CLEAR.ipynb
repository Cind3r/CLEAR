{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a97bcb8",
   "metadata": {},
   "source": [
    "# CLEAR\n",
    "\n",
    "Chargemaster Location-based Exploration for Affordability & Reform\n",
    "\n",
    "This is the notebook file primarily responsible for pre-processing data, attaching important information, and generating database files for the github page. Below you can find all information about how data is processed from the downloaded `.csv` files found on most hospital sites. This is an exploratory project focused on creating interactive visualzations and tools to better inform people about their healthcare. The repo can always be maintained by downloading the most current year data for the specific hospital and putting it through the scripts. It should be noted that this is NOT a comprehensive list, but it can potentially be scaled to a full working-standalone site with enough time. \n",
    "\n",
    "All pre-processing code is written in python. See the `.html` files for how the D3 visualizations work. \n",
    "\n",
    "## How it works (Copied from README)\n",
    "\n",
    "Hospitals that have been added to this 'web-app' are stored in a `.csv` file for quick look up and ease of access. This points to the loc of it's Charge Master `.parquet` file which is then queried for the specific proceedure. Hospitals are gathered from the CSV list based on a radius look-up provided by the user. If a hospital in the radius does not offer the service, it will not display the price point compared to others in the radius. \n",
    "\n",
    "## List of Hospitals\n",
    "\n",
    "These are the hospital's which data has been gathered and processed for thus far:\n",
    "\n",
    "| State    | Hospital Name                     | Zipcode     | Date                 | File Size    | Link                                                            |\n",
    "|----------|--------------------------------|-------------|-------------------|-------------|------------------------------------------------|\n",
    "| NC        | Duke University Hospital     |     27710    |      09/2025      |   3.32 GB   |                                                                   |\n",
    "| NC        | Wake Med                           |                   |                          |                   |                                                                 |\n",
    "| NC        | REX UNC                             |                   |                          |                   |                                                                 |\n",
    "\n",
    "## Outside Sources Used\n",
    "\n",
    "- zip_centroids.csv courtesy of SimpleMaps data\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bdabc1",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "CSV files are too large to store on github, thus they are downloaded locally, converted to the necessary format, then uploaded. If you want to perform conversions yourself you will need to find the specific hospital chargemaster and document in the notebook accordingly.\n",
    "\n",
    "Not all Charge Masters (CM) are formatted the same, as such, to keep this notebook from growing too large, custom python scripts will be made for unique CM's. This matters beccause some hospitals are regional or statewide 'chains' but can vary prices between locations. For example, \n",
    "\n",
    "**AdventHealth**\n",
    "- AdventHealth Orlando\n",
    "- AdventHealth Tampa\n",
    "- AdventHealth Hendersonville\n",
    "\n",
    "all are AdventHealth hospitals, but their prices and available procedures vary per location. However, the same script to clean and process their CM's works because the file structure doesn't change from loc to loc. Normally CM structure only changes from hospital to hospital (brand-wise), but I haven't looked at the majority of US hospitals so this statement might need to be amended. \n",
    "\n",
    "Think of this file as more of a \"**Controller**\" for the cleaning, while the cleaning process is performed by imported functions. Subsections from here on are labeled by State, be sure to check which Hospitals are in each subsection before uploading data. \n",
    "\n",
    "## Data Structure\n",
    "\n",
    "As the JS is grabbing the parquet files, we want the structure of each one to be similar even though it's not a centeral DB structure. This is more for performance/optimization and reducing the front-end coding needed as my JS is not as strong as my python tbh. \n",
    "\n",
    "#### Filenames for parquet:\n",
    "- generated using a seeded ID function in this notebook, which updates the .csv file that holds the index information for the hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55483ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospitals.csv updater/editor\n",
    "import hashlib\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"CLEAR-geoapi-2025\")\n",
    "csv_file = 'docs/data/hospitals.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# construct address for geocoding only (don't modify original data)\n",
    "def construct_geocoding_address(row):\n",
    "    # Build clean address from original components\n",
    "    address = f\"{row['address']}, {row['city']}, {row['state']} {row['zip']}\"\n",
    "    return address\n",
    "\n",
    "# get lat/lon from address with increased timeout and retry/delay\n",
    "def get_lat_lon(address, max_retries=3, delay=2):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            location = geolocator.geocode(address, timeout=5)\n",
    "            if location:\n",
    "                return location.latitude, location.longitude\n",
    "            else:\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding {address} (attempt {attempt+1}): {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None, None\n",
    "\n",
    "# generate short unique ID based on ['hospital'] + full composite address (base36, 8 chars)\n",
    "def generate_short_id(row):\n",
    "    full_address = construct_geocoding_address(row)\n",
    "    unique_string = f\"{row['name']}_{full_address}\"\n",
    "    hash_int = int(hashlib.md5(unique_string.encode()).hexdigest(), 16)\n",
    "    short_id = base36encode(hash_int)[:8]\n",
    "    return short_id\n",
    "\n",
    "# base36 encoding for shorter IDs\n",
    "def base36encode(number):\n",
    "    chars = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    if number == 0:\n",
    "        return '0'\n",
    "    result = ''\n",
    "    while number > 0:\n",
    "        number, i = divmod(number, 36)\n",
    "        result = chars[i] + result\n",
    "    return result\n",
    "\n",
    "# Add lat/lon and short_id to dataframe, set parquet_path to be '/data/prices/['state']/['id'].parquet'\n",
    "def update_dataframe(df):\n",
    "    \n",
    "    # Don't modify the address column - just use it for geocoding\n",
    "    def lat_lon_with_delay(row):\n",
    "        geocoding_address = construct_geocoding_address(row)\n",
    "        lat, lon = get_lat_lon(geocoding_address)\n",
    "        time.sleep(1)  # 1 second delay per request\n",
    "        return pd.Series([lat, lon])\n",
    "    \n",
    "    df[['lat', 'lon']] = df.apply(lat_lon_with_delay, axis=1)\n",
    "    df['id'] = df.apply(generate_short_id, axis=1)\n",
    "    df['parquet_path'] = df.apply(lambda row: f\"docs/data/hospitals/{row['state']}/{row['id']}.parquet\", axis=1)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    return\n",
    "\n",
    "update_dataframe(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
